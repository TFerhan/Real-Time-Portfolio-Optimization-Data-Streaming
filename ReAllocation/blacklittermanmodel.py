# -*- coding: utf-8 -*-
"""BlackLittermanModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qqVYMfCkmH_Qs_4NIWF3bwxaPzq3B2Xz
"""

import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
from scipy.stats import shapiro, anderson, kstest, ks_2samp, chisquare

data = requests.get("http://localhost:8082/api/dailyprices/weekly/ADH?start=2020-05-22&finish=2026-03-20")

sorted_data = {k: v for k, v in sorted(data.json().items(), key=lambda item: item[0], reverse=False)}

pd.DataFrame(sorted_data).T

data.json()

capitalisation_data = requests.get("http://localhost:8082/api/dailyprices/latest-capitalisations")

capitalisation_data.json()

d = data.json()

d

data_f = data.json()

data_f

sorted_data = {k: v for k, v in sorted(data_f.items(), key=lambda item: item[0], reverse=False)}

dg = pd.DataFrame(sorted_data).transpose()
dg.head()

d

def get_dataframe(data):
    rows = []
    for ticker, date_dict in data.items():
        for date_str, entry in date_dict.items():
            row = entry.copy()
            rows.append(row)

    df = pd.DataFrame(rows)
    return df

tf = get_dataframe(d)

tf

liquidity = requests.get("http://localhost:8082/api/dailyprices/average-titres-echanges")

liquidity.json()

avg_titres = pd.DataFrame.from_dict(liquidity.json(), orient='index').reset_index(drop=True)

capitalisations = pd.DataFrame.from_dict(capitalisation_data.json(), orient='index').reset_index(drop=True)
capitalisations

stocks_selected = ["AKT", "ATW", "BOA", "BCP", "MDP", "MUT", "DOH","IAM", "RIS", "TGC", "ADI", "IMO"]

avg_titres

capt_of_selected = capitalisations[capitalisations['ticker'].isin(stocks_selected)]
capt_of_selected = capt_of_selected.reset_index(drop=True)

capt_of_selected

benchmark_proportions = pd.DataFrame(columns=['ticker', 'benchmark_proportion'])
sum_of_cap = capt_of_selected['capitalisation'].sum()
for i in range(len(capt_of_selected)):
    ticker = capt_of_selected.loc[i, 'ticker']
    capitalisation = capt_of_selected.loc[i, 'capitalisation']/sum_of_cap
    benchmark_proportions = benchmark_proportions.append({'ticker': ticker, 'benchmark_proportion': capitalisation}, ignore_index=True)
benchmark_proportions

benchmark_proportions.to_csv('benchmark_proportions.csv', index=False)

benchmark_proportions["benchmark_proportion"].sum()

weekly_data = pd.DataFrame()
for ticker in stocks_selected:
    dt = requests.get(f"http://localhost:8082/api/dailyprices/weekly/{ticker}?start=2020-05-22&finish=2026-03-20").json()
    sorted_data = {k: v for k, v in sorted(dt.items(), key=lambda item: item[0], reverse=False)}
    df = pd.DataFrame(sorted_data).transpose()
    weekly_data = pd.concat([weekly_data, df], ignore_index=True)

weekly_data = weekly_data.reset_index(drop=True)
weekly_data



anticipated_benchmark_return = 0.0045

2.2/12

bon_tresor = 0.0018

weekly_data.to_csv("weekly_data.csv", index=False)

weekly_data = pd.read_csv("weekly_data.csv")

tickers = weekly_data['ticker'].unique()
weeks = weekly_data['week_start'].sort_values().unique()


returns_df = pd.DataFrame(index=weeks)

for ticker in tickers:
    ticker_data = weekly_data[weekly_data['ticker'] == ticker][['week_start', 'weekly_log_return']]
    ticker_data = ticker_data.set_index('week_start').reindex(weeks)
    returns_df[ticker] = ticker_data['weekly_log_return'].values

returns_df = returns_df.astype(float)

returns_df.cov().to_csv("covariance.csv")

covariance = pd.read_csv("covariance.csv", index_col=0)
benchmark_proportions = pd.read_csv("benchmark_proportions.csv")

covariance.to_dict()



covariance



covariance.info()

colg = covariance.columns.tolist()

covariance = returns_df.cov()

v = benchmark_proportions["benchmark_proportion"].values.reshape(1, -1)
cov = covariance.values

normalizing_factor = (anticipated_benchmark_return - bon_tresor)/((v @ cov @ v.T)[0][0])

anticipated_benchmark_return

expected_returns =  ( cov @ v.T )*normalizing_factor + bon_tresor
expected_returns

expected_returns_dict = {ticker: expected_returns[i][0] for i, ticker in enumerate(colg)}
expected_returns_dict

with open("expected_returns.json", "w") as f:
    json.dump(expected_returns_dict, f)

expected_returns_benchmark = v @ expected_returns
expected_returns_benchmark

returns_df

bl_tracking_matrix = covariance.copy()
stocks_selected = returns_df.columns.tolist()
for ticker in stocks_selected:
    var_column = returns_df[ticker].var()
    print(var_column)
    bl_tracking_matrix[ticker] = bl_tracking_matrix[ticker] / var_column
bl_tracking_matrix

analyste_confidence_level = 0.6

fr = pd.DataFrame(index = returns_df.columns.to_list(),columns=["expected_benchmark_returns_with_no_opininon","analyst_opinion","returns_adjusted_for_opinions","returns_adjusted_for_opinions_and_confidence" ])

fr

fr["expected_benchmark_returns_with_no_opininon"] = expected_returns

fr

returns_df.describe()

absolute_opinions = [0.001, 0, 0, 0, 0, 0, -0.003, -0.001, 0.002, 0.003,0]

fr["analyst_opinion"] = absolute_opinions
fr

fr["returns_adjusted_for_opinions"] = fr["expected_benchmark_returns_with_no_opininon"]+ bl_tracking_matrix.values @ fr["analyst_opinion"].values
fr

fr["returns_adjusted_for_opinions_and_confidence"] = analyste_confidence_level*fr["returns_adjusted_for_opinions"] + (1-analyste_confidence_level)*fr["expected_benchmark_returns_with_no_opininon"]
fr

import matplotlib.pyplot as plt

from pypfopt import EfficientFrontier, risk_models, expected_returns, plotting, objective_functions

ef = EfficientFrontier(fr["returns_adjusted_for_opinions"].values, covariance)

ef.max_sharpe()

ef.add_objective(objective_functions.L2_reg, gamma=0.002)

ef.portfolio_performance(verbose=True)

0.62*np.sqrt(52)

ef.max_sharpe()

f = [('AKT', 0.1446728641006508),
             ('ATW', 0.0912261402191613),
             ('BOA', 0.0740800635238359),
             ('BCP', 0.0571115190505854),
             ('MDP', 0.0383370631645343),
             ('MUT', 0.070759460642199),
             ('IAM', 0.0606601723966225),
             ('RIS', 0.0871255123374714),
             ('TGC', 0.1696701654562202),
             ('ADI', 0.1554814882278604),
             ('IMO', 0.0508755508808587)]
s = 0
for i in f:
    s += i[1]
s

fig, ax = plt.subplots()
plotting.plot_efficient_frontier(ef, ax=ax, show_assets=True)

plt.title("Efficient Frontier")
plt.show()

opt_port = pd.DataFrame(index = returns_df.columns.to_list(),columns=["optimized_portfolio_with_no_analyst_opinion","opinion_adjusted_optimized_portfolio","opinion_and_confidence_adjusted_portfolio"])
opt_port

opt_port_no_short = opt_port.copy()

from pypfopt.black_litterman import BlackLittermanModel
from pypfopt.risk_models import CovarianceShrinkage
from pypfopt.efficient_frontier import EfficientFrontier
from pypfopt.expected_returns import returns_from_prices

bl_returns = fr["returns_adjusted_for_opinions_and_confidence"] - bon_tresor

ef = EfficientFrontier(bl_returns, covariance)
ef.add_objective(lambda w: 0.01 * cp.norm(w, 2))
weights = ef.max_sharpe()
clean_weights = ef.clean_weights()
clean_weights

clean_weights, weights

import cvxpy as cp


mu = fr["returns_adjusted_for_opinions_and_confidence"].values - bon_tresor
Sigma = covariance.values

# Regularize covariance matrix (very important)
epsilon = 1e-6  # or tune this
Sigma_reg = Sigma + epsilon * np.eye(Sigma.shape[0])

n = len(mu)
w = cp.Variable(n)


target_return = 0.02
objective = cp.Minimize(cp.quad_form(w, Sigma_reg))
constraints = [cp.sum(w) == 1, w >= 0, mu @ w >= target_return]


# Solve the QP
prob = cp.Problem(objective, constraints)
prob.solve()


opt_port_no_short["opinion_and_confidence_adjusted_portfolio"] = w.value


opt_port_no_short

opt_port_no_short["opinion_and_confidence_adjusted_portfolio"].to_list()

returns_adj = fr["expected_benchmark_returns_with_no_opininon"].values - bon_tresor
cov_inv = np.linalg.inv(covariance.values)

numerator = cov_inv @ returns_adj
denominator = np.sum(numerator)

opt_port["optimized_portfolio_with_no_analyst_opinion"] = numerator / denominator

numerator, denominator

opt_port

returns_adj = fr["returns_adjusted_for_opinions"].values - bon_tresor
cov_inv = np.linalg.inv(covariance.values)

numerator = cov_inv @ returns_adj
denominator = np.sum(numerator)

opt_port["opinion_adjusted_optimized_portfolio"] = numerator / denominator
opt_port["opinion_adjusted_optimized_portfolio"].sum()

returns_adj = fr["returns_adjusted_for_opinions_and_confidence"].values - bon_tresor
cov_inv = np.linalg.inv(covariance.values)

numerator = cov_inv @ returns_adj
denominator = np.sum(numerator)

opt_port["opinion_and_confidence_adjusted_portfolio"] = numerator / denominator
opt_port

fr

opt_port["opinion_and_confidence_adjusted_portfolio"].values.transpose() @ fr["returns_adjusted_for_opinions_and_confidence"].values